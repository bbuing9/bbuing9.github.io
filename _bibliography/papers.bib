@STRING{iclr = {International Conference on Learning Representations (ICLR)}}
@STRING{icml = {Proceedings of the International Conference on Machine Learning (ICML)}}
@STRING{neurips = {Advances in Neural Information Processing Systems (NeurIPS)}}
@STRING{tmlr = {Transactions on Machine Learning Research (TMLR)}}

@STRING{emnlp = {Conference on Empirical Methods in Natural Language Processing (EMNLP)}}
@STRING{acl = {Annual Meeting of the Association for Computational Linguistics (ACL)}}
@STRING{naacl = {Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)}}
@STRING{eacl = {Conference of the European Chapter of the Association for Computational Linguistics (EACL)}}

@STRING{cvpr = {Conference on Computer Vision and Pattern Recognition (CVPR)}}
@STRING{eccv = {International Conference on Computer Vision (ICCV)}}
@STRING{iccv = {European Conference on Computer Vision (ECCV)}}

@STRING{colm = {Conference on Language Modeling (COLM)}}
@STRING{aaai = {AAAI Conference on Artificial Intelligence (AAAI)}}

@inproceedings{seo2025fast,
  title={Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning},
  author={Seo, Yeongbin and Lee, Dongha and Kim, Jaehyung and Yeo, Jinyoung},
  booktitle=neurips,
  year={2025},
  code={https://github.com/ybseo-ac/Conv},
  arxiv={2509.15188}
}
@inproceedings{kim2025robot,
  title={Robot-R1: Reinforcement Learning for Enhanced Embodied Reasoning in Robotics},
  author={Kim, Dongyoung and Park, Sumin and Jang, Huiwon and Shin, Jinwoo and Kim, Jaehyung and Seo, Younggyo},
  booktitle=neurips,
  year={2025},
  arxiv={2506.00070}
}
@inproceedings{bu2025personalized,
  title={Personalized LLM Decoding via Contrasting Personal Preference},
  author={Bu, Hyungjune and Jung, Chanjoo and Kang, Minjae and Kim, Jaehyung},
  booktitle=emnlp,
  year={2025},
  code={https://github.com/cleverscent/CoPe},
  arxiv={2506.12109},
  website={https://naughtymaltiz16.github.io/cope_project_page/}
}
@inproceedings{jang2025improving,
  title={Improving Chemical Understanding of LLMs via SMILES Parsing},
  author={Jang, Yunhui and Kim, Jaehyung and Ahn, Sungsoo},
  booktitle=emnlp,
  arxiv={2505.16340},
  year={2025}
}
@inproceedings{kim2025privacy,
  title={Personalized Language Models via Privacy-Preserving Evolutionary Model Merging},
  author={Kim, Kyuyoung and Shin, Jinwoo and Kim, Jaehyung},
  booktitle=emnlp,
  code={https://github.com/kykim0/PriME},
  arxiv={2503.18008},
  year={2025}
}
@inproceedings{kim2025debiasing,
  title={Debiasing Online Preference Learning via Preference Feature Preservation},
  author={Kim, Dongyoung and Yoon, Jinsung and Shin, Jinwoo and Kim, Jaehyung},
  booktitle=acl,
  code={https://github.com/kingdy2002/PFP},
  arxiv={2506.11098},
  year={2025}
}
@inproceedings{jang2025structural,
  title={Structural Reasoning Improves Molecular Understanding of LLM},
  author={Jang, Yunhui and Kim, Jaehyung and Ahn, Sungsoo},
  booktitle=acl,
  arxiv={2410.05610},
  year={2025}
}
@inproceedings{lee2025revise,
  title={{ReVISE}: Learning to Refine at Test-Time via Intrinsic Self-Verification},
  author={Lee, Hyunseok and Oh, Seunghyuk and Kim, Jaehyung and Shin, Jinwoo and Tack, Jihoon},
  booktitle=icml,
  code={https://github.com/seunghyukoh/revise},
  arxiv={2502.14565},
  year={2025}
}
@inproceedings{kim2025few,
  title={Few-shot Personalization of LLMs with Mis-aligned Responses},
  author={Kim, Jaehyung and Yang, Yiming},
  booktitle=naacl,
  code={https://github.com/bbuing9/Fermi},
  arxiv={2406.18678},
  year={2025}
}
@inproceedings{kim2025spread,
  title={Spread Preference Annotation: Direct Preference Judgment for Efficient LLM Alignment},
  author={Kim, Dongyoung and Lee, Kimin and Shin, Jinwoo and Kim, Jaehyung},
  booktitle=iclr,
  code={https://github.com/kingdy2002/SPA},
  arxiv={2406.04412},
  year={2025}
}

@article{feng2025alternative,
  title={Alternative Mixed Integer Linear Programming Optimization for Joint Job Scheduling and Data Allocation in Grid Computing},
  author={Feng, Shengyu and Kim, Jaehyung and Yang, Yiming and Boudreau, Joseph and Chowdhury, Tasnuva and Hoisie, Adolfy and Khan, Raees and Kilic, Ozgur O. and Klasky, Scott and Korchuganova, Tatiana and Nilsson, Paul and Outschoorn, Verena Ingrid Martinez and Park, David K. and Podhorszki, Norbert and Ren, Yihui and Suter, Frederic and Vatsavai, Sairam Sri and Yang, Wei and Yoo, Shinjae and Maeno, Tadashi and Klimentov, Alexei},
  journal={Future Generation Computer Systems},
  arxiv={2502.00261},
  year={2025}
}

@misc{gwak2025revisiting,
  title={Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces},
  author={Gwak, Minju and Son, Guijin and Kim, Jaehyung},
  arxiv={2510.06953},
  note={arXiv preprint},
  year={2025}
}

@misc{jung2025titok,
  title={{TiTok}: Transfer Token-level Knowledge via Contrastive Excess to Transplant {LoRA}},
  author={Jung, Chanjoo and Kim, Jaehyung},
  arxiv={2510.04682},
  note={arXiv preprint},
  year={2025}
}

@misc{koo2025amis,
  title={Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges},
  author={Koo, Hamin and Kim, Minseon and Kim, Jaehyung},
  arxiv={2511.01375},
  note={arXiv preprint},
  year={2025}
}


@misc{lee2025trainingfree,
  title={Training-free LLM Verification via Recycling Few-shot Examples},
  author={Lee, Dongseok and Hong, Jimyung and Kim, Dongyoung and Kim, Jaehyung},
  arxiv={2506.17251},
  code={https://github.com/dongseok1220/Referi},
  note={arXiv preprint},
  year={2025}
}

@misc{cho2025revisit,
  title={Revisit What You See: Disclose Language Prior in Vision Tokens for Efficient Guided Decoding of {LVLM}s},
  author={Cho, Beomsik and Kim, Jaehyung},
  arxiv={2506.09522},
  code={https://github.com/bscho333/ReVisiT},
  note={arXiv preprint},
  year={2025}
}

@misc{seo2025prior,
  title={Prior-based Noisy Text Data Filtering: Fast and Strong Alternative for Perplexity},
  author={Seo, Youngbin and Kim, Gayoung and Kim, Jaehyung and Yeo, Jinyoung},
  arxiv={2509.18577},
  note={arXiv preprint}, 
  year={2025}
}

@misc{lee2025collaborative,
  title={Collaborative LLM Inference via Planning for Efficient Reasoning},
  author={Lee, Byeongchan and Lee, Jonghoon and Kim, Dongyoung and Kim, Jaehyung and Shin, Jinwoo},
  arxiv={2506.11578},
  note={arXiv preprint},
  year={2025}
}

@misc{kim2025think,
  title={{LLMs} Think, But Not in Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models},
  author={Kim, Jieyong and Kim, Tongyoung and Yoon, Soojin and Kim, Jaehyung and Lee, Dongha},
  arxiv={2505.21082},
  note={arXiv preprint},
  year={2025}
}

@misc{koo2025extracting,
  title={EMCee: Improving Multilingual Capability of LLMs via Bridging Knowledge and Reasoning with Extracted Synthetic Multilingual Context},
  author={Koo, Hamin and Kim, Jaehyung},
  arxiv={2503.05846},
  code={https://github.com/hamin2065/EMCEI},
  note={arXiv preprint},
  year={2025}
}
